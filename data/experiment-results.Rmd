```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(AER)
library(kableExtra)
library(stargazer)
library(lubridate)
```

```{r read_data, include=FALSE}
df_all <- read_csv("clean_data_including_before_after.csv") %>%
  mutate(
    gender    = as_factor(gender),
    treatment = fct_relevel(as_factor(treatment), "BROAD", "NARROW", "LOW", "PARTIAL", "BEFORE", "AFTER"),
    scenario  = as_factor(scenario)
  )
```

In the analysis below we analyse the reservation wages across treatments: the smallest extra wage for which subjects prefer OPTION B over OPTION A, where OPTION B always requires decoding correctly 15 extra sequences compared to OPTION A. The extra payments start at $\$0.25$, if a subject always accepts the extra work, and increases in $\$0.25$ increments to $\$4.00$. If a subject never accepts the extra work, we code the reservation wage as $\$4.25$. First, we report our main results which test and estimate broad and narrow bracketing directly. We then report a non-preregistered heterogeneity analyis, as well as our pre-registered follow-up study collected after COVID-19 induced lockdowns. 


```{r summary_statistics, include=FALSE, message=FALSE}
summary_stats <- function(df) {
  # Only consider participants who finish the welcome screen
  df0 <- df %>%
    filter(!is.na(time_welcome)) %>%
    select(pid, scenario, inconsistent_choices) %>%
    pivot_wider(names_from = scenario, values_from = inconsistent_choices) %>%
    left_join(df %>% filter(scenario == "Scenario1"), by = "pid") %>%
    mutate(
      dropped_out   = is.na(time_questionnaire2),
      inconsistent1 = (Scenario1 > 0),
      inconsistent2 = (Scenario2 > 0)
    )

  df1 <- df0 %>%
    group_by(treatment) %>%
    summarize(
      observations  = n(),
      attrition     = paste0(round(100*mean(dropped_out), digits=1), "%"),
      final_obs     = as.character(sum(!dropped_out, na.rm=TRUE)),
      share_female  = round(mean(gender == "Female", na.rm=TRUE), digits=2),
      age           = round(mean(age, na.rm=TRUE),digits =1),
      tediousness   = round(mean(tediousness, na.rm=TRUE), digits=2),
      inconsistent1 = sum(inconsistent1, na.rm=TRUE),
      inconsistent2 = sum(inconsistent2, na.rm=TRUE)
    ) %>%
    mutate(treatment = as.character(treatment)) %>%
    ungroup()

  chi.p.value <- function(v) {
    round(chisq.test(df0$treatment, df0[[v]], correct=FALSE)$p.value, digits = 2)
  }

  df1 %>%
    rbind(c(
      treatment     = "p-value",
      observations  = "",
      attrition     = chi.p.value("dropped_out"),
      final_obs     = "",
      share_female  = chi.p.value("gender"),
      age           = chi.p.value("age"),
      tediousness   = chi.p.value("tediousness"),
      inconsistent1 = chi.p.value("inconsistent1"),
      inconsistent2 = chi.p.value("inconsistent2")
      ))
}

ss <- t(summary_stats(df_all %>% filter(treatment %in% c("NARROW", "LOW", "PARTIAL", "BROAD"))))
rownames(ss) <- c("", "Participants", "Attrition", "Final Participants", "Share Female", "Age", "Tediousness", "Scenario 1", "Scenario 2")

kbl(
  ss,
  booktabs = T,
  caption = "Summary statistics for main treatments.",
  digits=2,
  align='rrrrr',
  format='latex'
) %>%
  kable_styling(font_size=12) %>%
  row_spec(1, bold = TRUE, hline_after = TRUE) %>%
  row_spec(4, hline_after = TRUE) %>%
  row_spec(7, hline_after = TRUE) %>%
  pack_rows("Inconsistent Choices", 8, 9) %>%
  write("summary_statistics_main.tex")
```

```{r summary_stats_before_after, include=FALSE, message=FALSE}
ssba <- t(summary_stats(df_all %>% filter(treatment %in% c("NARROW", "BEFORE", "AFTER"))))

rownames(ssba) <- c("", "Participants", "Attrition", "Final Participants", "Share Female", "Age", "Tediousness", "Scenario 1", "Scenario 2")

kbl(
  ssba,
  booktabs = TRUE,
  caption = "Summary statistics for follow-up treatments",
  digits = 2,
  align='rrrr',
  row.names = 
    ) %>%
  kable_styling(font_size=12) %>%
  row_spec(1, bold = TRUE, hline_after = TRUE) %>%
  row_spec(4, hline_after = TRUE) %>%
  row_spec(7, hline_after = TRUE) %>%
  pack_rows("Inconsistent Choices", 8, 9) %>%
  write("summary_statistics_before_after.tex")
```

```{r attrition, message=FALSE, include=FALSE}
# Welcome time implies they saw the welcome screen
# time_instructions: they read instructions
# time_encryption_task: they did the practice tasks
# time_questionnaire: got to questionnaire
# time_task_preparation: they saw and completed the prep
# time_questionnaire2: they completed the study:
# wta1 in scenario1: they completed the first choice:

attrition_stats <- function(df) {
  paste_to_percent <- function(v) paste0(as.character(round(v)), "%")
  df0 <- df %>%
    filter(!is.na(time_welcome))
  df0 %>%
    # Count every person only once, not once per scenario
    filter(scenario == "Scenario1") %>% 
    group_by(treatment) %>%
    summarise(
      practice_tasks    = 100*sum(is.na(time_encryption_task))/n(),
      # FIXME: Check that time_task_preparation really is the page before the first choice
      study_description = 100*sum(is.na(time_task_preparation))/n(),
      answer1           = 100*sum(is.na(reservation_wage))/n(),
      learn_total_tasks = 100*sum(is.na(time_summary))/n(),
      finish_study      = 100*sum(is.na(time_questionnaire2))/n()
    ) %>%
    # FIXME: Use mutate across
    mutate(
      practice_tasks    = paste_to_percent(practice_tasks), 
      study_description = paste_to_percent(study_description),
      answer1           = paste_to_percent(answer1),
      learn_total_tasks = paste_to_percent(learn_total_tasks),
      finish_study      = paste_to_percent(finish_study)
    )
}

attrition_stats(df_all) %>%
  kbl(
    booktabs = T,
    caption = "Attrition in \\% by a given stage",
    digits=0,
    col.names = c("Treatments", "Practice", "Choice 1", "Answer 1", "Learn Tasks", "End"),
    align = 'lrrrrr'
  ) %>%
  kable_styling(latex_options="striped", font_size=12) %>%
  pack_rows("Main", 1, 4) %>%
  pack_rows("Follow Up", 5, 6) %>%
  write("attrition_statistics.tex")
```

## Main Results

```{r means_data, message=FALSE}
consistent_df_all <- df_all %>% 
  # Keep only choices which were done consistently (drop only that scenario)
  filter(inconsistent_choices == 0) %>%
  # Keep only people who finish the study and hence the tasks
  filter(!is.na(time_questionnaire2)) %>%
  select(pid, scenario, treatment, reservation_wage, inconsistent_choices, everything())

consistent_dfba <- consistent_df_all %>%
  filter(treatment %in% c("NARROW", "BEFORE", "AFTER"))
consistent_df <- consistent_df_all %>%
  filter(treatment %in% c("LOW", "NARROW", "PARTIAL", "BROAD"))

means_data <- function(df) {
  paste_to_percent <- function(v) paste0(as.character(round(v)), "%")
  df %>%
    filter( !is.na(reservation_wage)) %>%
    group_by(scenario, treatment) %>%
    summarise(
      res_wage   = mean(reservation_wage),
      standard_deviation = sd(reservation_wage),
      share_upper_bound = paste_to_percent(100 * mean(reservation_wage > 4.01)),
      N = n()
    ) %>%
    ungroup()
}

table_of_means_data <- function(means_df, caption, ntreatments = 4) {
  kbl(
    means_df,
    col.names = c("Treatment", "Res. Wage", "Std Dev", "% upper bound", "N"),
    booktabs = T,
    caption = caption,
    align = 'lrrrr',
    digits=2
  ) %>%
    kable_styling(latex_options="striped", font_size=12) %>%
    pack_rows("Scenario 1", 1, ntreatments) %>%
    pack_rows("Scenario 2", ntreatments + 1, 2*ntreatments)
}

consistent_df %>%
  means_data() %>%
  select(-scenario) %>%
  table_of_means_data("Means of main treatments by scenario")
```

```{r bar_plots, message=FALSE, warning=FALSE}
raw_bar_plot <- ggplot(consistent_df, aes(x = reservation_wage)) +
  geom_bar(aes(y = ..prop..)) +
  facet_grid(treatment ~ scenario) +
  labs(x = "Reservation Wage", y = "Proportion")

ggsave("bar_plot.png", plot = raw_bar_plot, "png")
```

```{r kernel_density_plots, message=FALSE, warning=FALSE}
kernel_density_plot <- ggplot(consistent_df, aes(x = reservation_wage, group = treatment, color = treatment)) +
  geom_density() +
  facet_wrap(~ scenario) +
  labs(x = "Reservation Wage", y = "Density")

ggsave("density_plot.png", plot = kernel_density_plot, "png")
```


```{r means_data_on_page, message=FALSE}
january1 <- ymd("20200101")

consistent_df_presentation_on_page <- consistent_df %>%
  filter(!(treatment == "NARROW" & date(session_date) <= january1))

consistent_df_presentation_on_page %>%
  means_data() %>%
  select(-scenario) %>%
  table_of_means_data(
    "Means of main treatments by scenario, restricting NARROW to sessions where baseline is revealed on first choice page."
  ) %>%
  write("means_presentation_on_page.tex")
```

```{r means_data_before_page, message=FALSE}
consistent_df_presentation_before_page <- consistent_df %>%
  filter(!(treatment == "NARROW" & date(session_date) >= january1))

consistent_df_presentation_before_page %>%
  means_data() %>%
  select(-scenario) %>%
  table_of_means_data(
    "Means of main treatments by scenario, restricting NARROW to sessions where baseline is revealed right before the first choice page."
  ) %>%
  write("means_presentation_before_page.tex")
```


```{r regression_scenarios_pooled, echo=FALSE, message=FALSE, include=FALSE}
lm_pooled <- lm(reservation_wage ~ scenario + treatment, data = consistent_df)
lm_by_scenario <- lm(reservation_wage ~ scenario*treatment, data = consistent_df)

stargazer(lm_pooled, lm_by_scenario,
          title="Linear Regressions of reservation wages by treatment and scenario, with and without interaction effects",
          header=FALSE, 
          omit.stat=c("adj.rsq", "ser", "ll", "wald"),
          dep.var.labels="Reservation wage",
          column.labels=c("Without Interactions", "With Interactions"),
          model.names=FALSE,
          star.char=c("", "", ""),
          notes = c("Standard errors in parentheses."),
          digits = 2,
          label = "tab:linear-regressions",
          notes.append = FALSE
          # se = list(NULL, NULL, NULL, se12_clustered),
          # t = list(NULL, NULL, NULL, t12_clustered),
          # p = list(NULL, NULL, NULL, p12_clustered),
          ) %>%
  write("linear_regression_pooled_and_by_scenario.tex")
```

\begin{result}
We reject Hypothesis \ref{hyp:broad} that individuals bracket effort decisions broadly.
\end{result}

Both Tables \ref{tab:means_data} and \ref{tab:mwu_tables} resoundingly reject broad bracketing as per Hypothesis \ref{hyp:broad} since reservation wages are different for NARROW, BROAD, and PARTIAL, despite equal outcome sets.\footnote{See \ref{raw_data_plots} in Appendix \ref{appendix:additional-results} for bar plots and kernel density plots of the raw reservation wage data by treatment and scenario.} For example, the average extra reservation wage of the BROAD treatment in Scenario 1 is $\$2.88$ compared to $\$2.07$ in NARROW and $\$2.50$ in PARTIAL. Based on Wilcoxon rank-sum tests reported in Table \ref{tab:mwu_tables}, we reject that BROAD and NARROW are equal with a p-value of less than $0.001$ and that BROAD and PARTIAL are equal with a p-value of $0.012$ in Scenario 1.\footnote{Since there are ties in our data -- there are multiple people with the same reservation wage -- the test we compute uses a normal approximation to the test statistic (which does not assume that the data is normal, but that the test statistic itself is normal).} Similar results hold for Scenario 2. Notice that the reservation wage of Scenario 2 slightly decreases (statistically remains constant) in PARTIAL, which we attribute to either genuine non-convex disutility or, more likely, to some narrowly bracketed framing effect possibly due to the order of choices. 


```{r mwu_tables, warning=FALSE, message=FALSE}
options(knitr.kable.NA = '')

col_treat <- c("NARROW", "PARTIAL", "BROAD");
row_treat <- c("PARTIAL", "BROAD", "LOW");

pvalue_to_char <- function(p) {
  ifelse(p < 0.001, "$< 0.001$", paste0("$", as.character(round(p, digits=3)), "$"))
}

wilcox_pvalue <- function(x,y) pvalue_to_char(wilcox.test(x, y, exact=TRUE)$p.value)
t_pvalue <- function(x,y) pvalue_to_char(t.test(x,y)$p.value)

get_mwu <- function(df, f_pvalue) {
  n <- df$reservation_wage[df$treatment == "NARROW"]
  l <- df$reservation_wage[df$treatment == "LOW"]
  p <- df$reservation_wage[df$treatment == "PARTIAL"]
  b <- df$reservation_wage[df$treatment == "BROAD"]
  mwu_broad <- c(f_pvalue(b, n), f_pvalue(b, l),f_pvalue(b,p))
  mwu_narrow <- c(NA , f_pvalue(n,l),f_pvalue(n,p))
  mwu_low <- c(NA, NA, f_pvalue(l,p))
  (mwu_table1 <- tibble(Treatments = c("NARROW", "LOW", "PARTIAL"), BROAD = mwu_broad, NARROW = mwu_narrow, LOW = mwu_low))
}

mwu_table1 <- get_mwu(filter(consistent_df, scenario == "Scenario1"), wilcox_pvalue)
mwu_table2 <- get_mwu(filter(consistent_df, scenario == "Scenario2"), wilcox_pvalue)
t_table1 <- get_mwu(filter(consistent_df, scenario == "Scenario1"), t_pvalue)
t_table2 <- get_mwu(filter(consistent_df, scenario == "Scenario2"), t_pvalue)

kbl(
  rbind(mwu_table1, mwu_table2),
  escape=FALSE,
  booktabs=T,
  caption="Between-treatment p-values for main treatments based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation.",
  align="lccc"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  pack_rows("Scenario 1", 1, 3) %>%
  pack_rows("Scenario 2", 4, 6)
```

```{r mwu_tables_on_page, message=FALSE, warning=FALSE}
mwu_table1_presentation <- get_mwu(filter(consistent_df_presentation_on_page, scenario == "Scenario1"), wilcox_pvalue)
mwu_table2_presentation <- get_mwu(filter(consistent_df_presentation_on_page, scenario == "Scenario2"), wilcox_pvalue)

kbl(
  rbind(mwu_table1_presentation, mwu_table2_presentation),
  escape=FALSE,
  booktabs=T,
  caption="Between-treatment p-values for main treatments based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation. Restricted to those sessions of NARROW where baseline is revealed only on first choice page.",
  align="lccc"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  pack_rows("Scenario 1", 1, 3) %>%
  pack_rows("Scenario 2", 4, 6) %>%
  write("mwu_presentation_on_page.tex")
```

```{r mwu_narrow_v_narrow, message=FALSE, warning=FALSE}
narrow_before_page <- consistent_df_presentation_before_page %>%
  filter(treatment == "NARROW")
narrow_on_page <- consistent_df_presentation_on_page %>%
  filter(treatment == "NARROW")

mwu_nvn1 <- wilcox_pvalue(
  narrow_before_page$reservation_wage[narrow_before_page$scenario == "Scenario1"],
  narrow_on_page$reservation_wage[narrow_before_page$scenario == "Scenario1"]
  )

mwu_nvn2 <- wilcox_pvalue(
  narrow_before_page$reservation_wage[narrow_before_page$scenario == "Scenario2"],
  narrow_on_page$reservation_wage[narrow_before_page$scenario == "Scenario2"]
  )

mwu_table_nvn <- tibble(Scenarios = c("Scenario 1", "Scenario 2"), `Wilcoxon Test` = c(mwu_nvn1, mwu_nvn2))
kbl(
  mwu_table_nvn,
  escape=FALSE,
  booktabs=T,
  caption="Between-treatment p-values for NARROW when information on baseline is presented for the first time right before the first choice or exactly on the first choice page. Based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation.",
  align="lr"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  write("mwu_narrow_v_narrow.tex")
```

```{r mwu_tables_before_page, message=FALSE, warning=FALSE}
mwu_table1_presentation_before_page <- get_mwu(filter(consistent_df_presentation_before_page, scenario == "Scenario1"), wilcox_pvalue)
mwu_table2_presentation_before_page <- get_mwu(filter(consistent_df_presentation_before_page, scenario == "Scenario2"), wilcox_pvalue)

kbl(
  rbind(mwu_table1_presentation_before_page, mwu_table2_presentation_before_page),
  escape=FALSE,
  booktabs=T,
  caption="Between-treatment p-values for main treatments based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation. Restricted to those sessions of NARROW where baseline is revealed right before the first choice page.",
  align="lccc"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  pack_rows("Scenario 1", 1, 3) %>%
  pack_rows("Scenario 2", 4, 6) %>%
  write("mwu_presentation_before_page.tex")
```

\begin{result}
We fail to reject Hypothesis \ref{hyp:narrow} that individuals bracket effort decisions narrowly.
\end{result}

The same comparisons of mean reservation wages via Wilcoxon rank-sum tests fail to reject narrow bracketing, where we compare means in LOW and NARROW, which have identical choice sets, but different endowments. In scenario 1, the Wilcoxon rank-sum test fails to reject that the mean of $\$2.30$ in LOW is different from the mean of $\$2.07$ in NARROW (p-value of $0.117$), and in scenario 2 fails to reject that $\$2.74$ in LOW is different from $\$2.70$ in NARROW (p-value of $0.704$) -- see Table \ref{tab:means_data} for the means and Table \ref{tab:mwu_tables} for the test p-values.

```{r kappa_estimates, results='asis'}
kappa_formula <- function(broad_label) {
  as.formula(paste0('reservation_wage ~ I(scenario == "Scenario1")*(a1*I(treatment == "',
                    broad_label,
                    '") + b1*I(treatment == "LOW") + I(a1*(1 - k) + b1*k)*I(treatment == "NARROW")) + I(scenario == "Scenario2")*(a2*I(treatment == "',
                    broad_label,
                    '") + b2*I(treatment == "LOW") + I(a2*(1 - k) + b2*k)*I(treatment == "NARROW"))'))
}

kappa_nls <- function(df, included_broad, excluded_broad, genders_included) {
  nls(
    kappa_formula(included_broad),
    start=list(a1=1, a2=1, b1=0.5, b2=0.5,k=0.1),
    data=filter(df, treatment != excluded_broad, gender %in% genders_included)
  )
}

get_kappas <- function(df) {
  kappa         <- kappa_nls(df, "BROAD", "PARTIAL", c("Male", "Female", "Other"))
  kappa_male    <- kappa_nls(df, "BROAD", "PARTIAL", c("Male"))
  kappa_female  <- kappa_nls(df, "BROAD", "PARTIAL", c("Female"))
  pkappa        <- kappa_nls(df, "PARTIAL", "BROAD", c("Male", "Female", "Other"))
  pkappa_male   <- kappa_nls(df, "PARTIAL", "BROAD", c("Male"))
  pkappa_female <- kappa_nls(df, "PARTIAL", "BROAD", c("Female"))

  kappas <- list(
    kappa, kappa_male, kappa_female,
    pkappa, pkappa_male, pkappa_female
  )
}

kappa_names <- list(
  "BROAD All", "BROAD Male", "BROAD Female",
  "PARTIAL All", "PARTIAL Male", "PARTIAL Female"
)

clean_kappa <- function(k, name) {
  sumk <- summary(k)
  observationsk <- length(sumk$residuals)
  terms <- row.names(sumk$coef)
  dfk <- as.data.frame(sumk$coef)
  dfk$terms <- terms
  dfk %>%
    mutate(
      std.err      = `Std. Error`,
      p.value      = `Pr(>|t|)`,
      estimate     = `Estimate`
    ) %>%
    select(terms, estimate, std.err) %>%
    pivot_longer(!terms, names_to = "type", values_to = "value") %>%
    mutate(value = round(value, digits = 2)) %>%
    mutate(value = if_else(.$type == "std.err", paste0("(", value, ")"), paste0(value))) %>%
    # Add the number of observations
    rbind(tibble(terms = "N", type = "N", value = observationsk)) %>%
    # Put name of model as column header to tell models apart after joining
    rename(!!name:=value)
}

prepare_kappas <- function(df) {
  map2(get_kappas(df), kappa_names, ~ clean_kappa(.x, .y)) %>%
    reduce(left_join, by = c("terms", "type")) %>%
    select(!type) %>%
    mutate(Terms = dplyr::recode(terms,
                                 'a1' = 'S1 broader ($B_1$)',
                                 'a2' = 'S2 broader ($B_2$)',
                                 'b1' = 'S1 narrow ($N_1$)',
                                 'b2' = 'S2 narrow ($N_2$)',
                                 'k'  = '$\\kappa$',
                                 'N'  = "Observations"
                                 )) %>%
    select(Terms, everything()) %>%
    select(-terms)
}

prepare_kappas(consistent_df) %>%
  kbl(
    booktabs = TRUE,
    align = "c",
    format = "latex",
    caption = "Estimates of $\\kappa$ when the broader option is BROAD or PARTIAL respectively. Narrow option is always LOW, $\\kappa$ estimates the convex combination between the broader and the narrow option, with $\\kappa = 0$ indicating equality with the broader option.",
    escape = FALSE
  ) %>%
  kable_styling(full_width = TRUE) %>%
  collapse_rows(columns = 1, valign = "top", latex_hline = "major") %>%
  row_spec(9, bold = TRUE)
```

```{r kappas_on_page, include=FALSE, message=FALSE}
prepare_kappas(consistent_df_presentation_on_page) %>%
  kbl(
    booktabs = TRUE,
    align = "c",
    format = "latex",
    caption = "Estimates of $\\kappa$ when the broader option is BROAD or PARTIAL respectively. Narrow option is always LOW, $\\kappa$ estimates the convex combination between the broader and the narrow option, with $\\kappa = 0$ indicating equality with the broader option.",
    escape = FALSE
  ) %>%
  kable_styling(full_width = TRUE) %>%
  collapse_rows(columns = 1, valign = "top", latex_hline = "major") %>%
  row_spec(9, bold = TRUE) %>%
  write("kappas_presentation_on_page.tex")
```



One problem with comparing means by scenario is that this allows for multiple tests. While we only have two scenarios and lead to identical results for BROAD compared to the other treatments, we would like a more generally valid test. In our pre-registration, we specified running a linear regression with a single treatment effect averaged across scenarios. This essentially averages the reservation wages across scenarios by treatment and compares them. While this test rejects that BROAD is equal to NARROW or PARTIAL --- see \ref{tab:linear-regressions} in Appendix \ref{appendix:additional-results} --- it is conceptually the wrong test, as is illustrated by its failure to reject that NARROW and PARTIAL are equal. The reservation wage in PARTIAL is once above and once below the reservation wage in NARROW, which leads to similar average reservation wages. The reason this is conceptually the wrong test is made clear by Hypotheses \ref{hyp:narrow} and \ref{hyp:broad}, which apply at the level of full choices, which means at the level of scenarios. 

The general test we propose is to estimate the average degree of narrow bracketing across scenarios. Rather than averaging the reservation wages first and then estimating narrow bracketing, we would like to to estimate narrow bracketing per scenario and then average this. One way to do this is to realize that we can write the reservation wage in NARROW as a convex combination as follows:

\begin{equation*}
  m_{NARROW} = (1 - \kappa) \cdot m_{BROAD} + \kappa \cdot m_{NARROW}
\end{equation*}

where $\kappa$ is the degree of narrow bracketing. If $\kappa = 0$ we have broad bracketing, if $\kappa = 1$ we have narrow bracketing. Based on this we run the following non-linear model: 
\begin{align*}
  Y_{i,s,t} & = B_{s} \mathbbm{1}(t = BROAD) + N_{s} \mathbbm{1}(t = LOW) + ((1 - \kappa_{B}) \cdot B_{s} + \kappa_{B} \cdot N_{s}) \mathbbm{1}(t = NARROW) + \varepsilon_{i,s,t} \\
  Y_{i,s,t} & = B_{s} \mathbbm{1}(t = PARTIAL) + N_{s} \mathbbm{1}(t = LOW) + ((1 - \kappa_{P}) \cdot B_{s} + \kappa_{P} \cdot N_{s}) \mathbbm{1}(t = NARROW) + \varepsilon_{i,s,t} 
\end{align*}

where $i$ is the individual, $s$ the scenario, and $t$ the treatment. If we thought that there is a fraction $\kappa$ of the population that brackets exactly narrowly, and the rest brackets exactly broadly, then the above would identify this $\kappa$. This estimation allows us to combine all scenarios, and provides the average degree of narrow bracketing. It also allows $\kappa$ to fall outside the interval $[0,1]$, which can happen under non-convex disutility or because people engage in other types of bracketing than full broad or narrow bracketing.\footnote{As an example of non-convex disutility, suppose that the tasks 1 to 10 are unpleasant, that tasks 11 to 20 are easy due to warm-up, while tasks 21 to 30 are really unpleasant. Then a person who has to do 15 tasks but is asked like in NARROW treatment to do 15 vs 0 additional tasks may well think that these 15 additional tasks are \emph{easier} than the first 15 tasks if they take their baseline into account only partially. Thus they would be more willing than participants in LOW who in turn are more willing to work than participants in BROAD, hence $\kappa$ would fall outside the $[0,1]$ interval.}

We estimate the above regression via non-linear least squares (NLS, \cite{gallant1975nonlinear}) and report the results in Table \ref{tab:kappa_estimates}, where we use both the BROAD and the PARTIAL as the broader treatment: thus we estimate $\kappa$ for money and work (BROAD) as well as just work (PARTIAL) bracketing. The main take-away is that this strongly rejects equality of PARTIAL and NARROW (column 4, $\kappa = 1.53$, standard error of $0.61$), because it takes the reversed ranking of reservation wages into account. In order for NLS to provide credible standard errors however, we need the means between the broader treatment and LOW to be sufficiently different across all scenarios jointly --- which is just our identification assumption again! Our identication assumption holds for BROAD compared to LOW (since it holds in Scenario 1), but is unlikely to hold for PARTIAL compared to LOW, given how similar they are. This is reflected in the noisy (and untrustworthy) standard errors for the PARTIAL treatment in column 4. Despite the standard errors of the NLS-estimate probably being untrustworthy, the estimate of $\kappa$ strongly favors narrow over broad bracketing.\footnote{This remains true when we restrict observations of NARROW to late observations where participants find out their baseline on their first choice page only, but the standard errors being even larger, both from sample size and due to the blown up standard errors from male participants.} 

Conceptually, this kind of approach seems the most conceptually sound to us --- although there are probably better econometric estimation strategies than NLS. In addition to avoiding multiple tests, it also allows for joint identifcation of bracketing and preferences, the benefit of which we highlight in the next part.

```{r tobit_tables, knitr.kable.NA = '', results='asis', message=FALSE}
library(AER)

mtobit <- consistent_df %>%
  # Too few observations of 'Other' gender for estimation, get error in stargazer
  filter(gender != "Other") %>%
  mutate(
    gender    = droplevels(gender),
    treatment = droplevels(treatment)) %>%
  rename(
    Gender      = gender,
    Age         = age,
    Tediousness = tediousness,
    Scenario    = scenario
  ) %>%
  split(.$treatment) %>%
  map( ~ tobit(
        reservation_wage ~ Scenario + Gender + Age + Tediousness,
        left = -Inf,
        right = 4.25,
        data = .x
      ))

# tobit_estimates <- tobit_models %>%
#   map_df(~ as.data.frame(t(as.matrix(coef(.)))))

stargazer(mtobit$BROAD, mtobit$NARROW, mtobit$LOW, mtobit$PARTIAL,
          title="Determinants of bracketing across scenarios via Tobit Regressions (right censored at \\$4.25).",
          header=FALSE, 
          omit.stat=c("adj.rsq", "ser", "ll", "wald"),
          dep.var.labels="Reservation wage",
          column.labels=c("BROAD", "NARROW", "LOW", "PARTIAL"),
          model.names=FALSE,
          star.char=c("", "", ""),
          covariate.labels=c("Scenario 2", "Female", "Age", "Tediousness"),
          notes = c("Standard errors in parentheses."),
          digits = 2,
          label = "tab:tobit_tables",
          notes.append = FALSE
          # se = list(NULL, NULL, NULL, se12_clustered),
          # t = list(NULL, NULL, NULL, t12_clustered),
          # p = list(NULL, NULL, NULL, p12_clustered),
          )
```

## Heterogeneity, Joint Identification, and Gender Differences

We further explore the determinants of effort decisions across treatment with a set of (non pre-registered) estimates of $\kappa$ by gender as well as Tobit regressions. The gender specific estimates of $\kappa$ for BROAD versus LOW show that there is no major difference in the degree of narrow bracketing as measured by $\kappa$. This holds despite the fact that the difference in reservation wage for women in scenario 1 is $\$0.91$ in Scenario 1 and $\$0.21$ in Scenario 2 (the difference between S1 broader and S1 narrow in Table \ref{tab:kappa_estimates}), while these differences are only $\$0.42$ and $\$0.23$ for men. This highlights our next result:

\begin{result}
We see no difference in bracketing by gender, but narrow bracketing is costlier for women than men due to higher convexity of disutility.
\end{result}

This highlights the need for direct estimation of the degree of narrow bracketing via $\kappa$, which jointly estimates the preferences -- here the change in reservation wage between scenarios -- and bracketing. The reason is that the more linear the preferences are, the more similar behavior under narrow and broad bracketing is, which means that the reservation wage changes less even if the person brackets narrowly. Since in our dataset it so happened that women had a larger change in their reservation wage as measured by the difference between LOW and BROAD, they paid a higher cost from narrow bracketing. If instead we focused on whether the difference in reservation wage was significant and large as a proxy for narrow bracketing, we would wrongly conclude that women bracket more narrowly than men, another illustration why focusing on reservation wages rather than $\kappa$ is conceptually unhelpful.

In the Tobit regressions, we regress, separately for each treatment, the reservation wages choices on age, gender and the self-report of perceived tediousness, controlling for the Scenarios. In particular we are interested to check if there are within treatment gender differences, as already found in different settings \citep[e.g.][]{koch2019correlates}. Since we have a substantial fraction of choices by individuals that are never willing to decode extra sequences, our data are right-censored at $\$4.25$. We report the estimation results in Table \ref{tab:tobit_tables}. 

The Tobit regressions in Table \ref{tab:tobit_tables} tell a similar story. Age has no clear effect on the results, while we observe a positive correlation between tediousness and the reservation wage in all treatments, although this is not always significant.

Let us conclude this part by highlighting a field setting where such joint identification is almost possible and is likely to matter. In a nice study of monopsony power, \cite{dubeJacobsNaiduSiddarth2020monopsonyOnlineMarkets} measure labor supply elasticities on MTurk. In their estimation of employers' market power, they assume myopic workers who essentially narrowly bracket. While this does not affect the reduced-form measure of labor supply elasticity, if we treat this estimate as if it was all driven by preferences rather than bracketing, this may provide the wrong predictions to responses in labor market policies and designs. Their data does allow for our simple strategy of joint identification, since they only have a single observation per worker, but this may be possible by collecting multiple observations per worker, or making additional assumptions about the population-level bracketing and preferences.



## Study 2: an Attempt to Debias

The treatments BEFORE and AFTER are exactly identical to the NARROW treatment, except for describing additional sequences as "additional sequences before" or "additional sequences after" the 15 required tasks. We report the means by Scenario and treatment and the Wilcoxon tests in Tables \ref{tab:before_after} and \ref{tab:mwu_before_after} similarly to our main treatments. We compare BEFORE and AFTER with the NARROW treatment with which they are identical \emph{except} for the additional highlighting of the tasks as "before" or "after" the baseline tasks. In both BEFORE and AFTER the extra reservation wage is higher than in NARROW, but in both cases this difference is not statistically significant ($p-values$ $>0.091$). In Appendix \ref{appendix:additional-results}, we however show that the AFTER treatment is statistically significantly different from NARROW when we limit ourselves to those observations in NARROW that received their information about baseline on the first choice page only, which indicates a partial success of debiasing.

\begin{result}
    Reminding participants of additional tasks alone has no discernible affect, while emphasizing the additional costs due to convexity (suggestively) reduces the impact of narrow bracketing.
\end{result}

```{r before_after, message = FALSE}
means_data(consistent_dfba) %>%
  mutate(treatment = factor(treatment, levels = c("NARROW", "BEFORE", "AFTER"), ordered = TRUE)) %>%
  arrange(scenario, treatment) %>%
  select(-scenario) %>%
  table_of_means_data(
    "Means of treatments with identical presentation and outcomes but without framing (NARROW), or framing additional tasks as before (BEFORE) or after (AFTER) the baseline tasks",
    ntreatments = 3
  )
```

```{r before_after_on_page, message=FALSE}
consistent_dfba_on_page <- consistent_dfba %>%
  filter(!(treatment == "NARROW" & date(session_date) <= january1))
  
means_data(consistent_dfba_on_page) %>%
  mutate(treatment = factor(treatment, levels = c("NARROW", "BEFORE", "AFTER"), ordered = TRUE)) %>%
  arrange(scenario, treatment) %>%
  select(-scenario) %>%
  table_of_means_data(
    "Restricting NARROW to sessions done with presentation on choice page only. Means of treatments with identical presentation and outcomes but without framing (NARROW), or framing additional tasks as before (BEFORE) or after (AFTER) the baseline tasks",
    ntreatments = 3
  ) %>%
  write("before_after_on_page.tex")
```

```{r mwu_before_after, warning=FALSE}
options(knitr.kable.NA = '')

col_treat <- c("NARROW", "BEFORE");
row_treat <- c("BEFORE", "AFTER");

get_mwu_ba <- function(df, f_pvalue) {
  n <- df$reservation_wage[df$treatment == "NARROW"]
  b <- df$reservation_wage[df$treatment == "BEFORE"]
  a <- df$reservation_wage[df$treatment == "AFTER"]
  mwu_narrow <- c(f_pvalue(n,b),f_pvalue(n,a))
  mwu_before <- c(NA,f_pvalue(b,a))
  (mwu_table1 <- tibble(Treatments = c("BEFORE", "AFTER"), NARROW = mwu_narrow, BEFORE = mwu_before))
}

mwu_table1ba <- get_mwu_ba(filter(consistent_dfba, scenario == "Scenario1"), wilcox_pvalue)
mwu_table2ba <- get_mwu_ba(filter(consistent_dfba, scenario == "Scenario2"), wilcox_pvalue)

kbl(
  rbind(mwu_table1ba, mwu_table2ba),
  escape=FALSE,
  booktabs=T,
  caption="Between-treatment p-values for NARROW, BEFORE, and AFTER treatments based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation.",
  align="lcc"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  pack_rows("Scenario 1", 1, 2) %>%
  pack_rows("Scenario 2", 3, 4)
```

```{r mwu_before_after_on_page, message=FALSE, include=FALSE}
mwu_table1ba_on_page <- get_mwu_ba(filter(consistent_dfba_on_page, scenario == "Scenario1"), wilcox_pvalue)
mwu_table2ba_on_page <- get_mwu_ba(filter(consistent_dfba_on_page, scenario == "Scenario2"), wilcox_pvalue)

kbl(
  rbind(mwu_table1ba_on_page, mwu_table2ba_on_page),
  escape=FALSE,
  booktabs=T,
  caption=" Between-treatment p-values for NARROW, BEFORE, and AFTER treatments based on two-sided Wilcoxon rank-sum tests, treating each individual in each scenario as a single independent observation. Restricted to choices of NARROW when baseline is mentioned on choice page first.",
  align="lcc"
) %>%
  kable_styling(font_size = 12, latex_options="striped") %>%
  pack_rows("Scenario 1", 1, 2) %>%
  pack_rows("Scenario 2", 3, 4) %>%
  write("mwu_before_after_on_page.tex")
```
